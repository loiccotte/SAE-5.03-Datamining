{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ddce0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques chargées !\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Bibliothèques chargées !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143dcdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées : 1848 avis et 1643 mots de vocabulaire.\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers le fichier \n",
    "pkl_path = 'vectorisation-du-texte/output/config_L1_S1_LEM1_NG1_FINAL.pkl'\n",
    "\n",
    "#(Minuscules + Stopwords + Lemmatisation + Unigrammes)\n",
    "\n",
    "# Chargement du dictionnaire complet\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Extraction des éléments\n",
    "X = data['X_normalized']       # La matrice numérique (Avis)\n",
    "y = data['target']             # La cible (Positif/Négatif)\n",
    "features = data['feature_names'] # La liste des mots (Vocabulaire)\n",
    "vectorizer = data['tfidf_vectorizer'] # L'outil pour transformer un nouveau texte\n",
    "\n",
    "print(f\"Données chargées : {X.shape[0]} avis et {X.shape[1]} mots de vocabulaire.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd25f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement en cours (patience)...\n",
      "Meilleur score : 88.43%\n",
      "Meilleurs paramètres : {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     négatif       0.84      0.93      0.88       188\n",
      "     positif       0.92      0.81      0.86       182\n",
      "\n",
      "    accuracy                           0.87       370\n",
      "   macro avg       0.88      0.87      0.87       370\n",
      "weighted avg       0.88      0.87      0.87       370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yanni\\BUT\\BUT3\\SAE Data Mining\\SAE-5.03-Datamining\\venv\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Classification avec régression logistique (Sentiments) :\n",
    "# 1. Séparation des données (80% pour apprendre, 20% pour tester)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Création du modèle avec GridSearch pour trouver les meilleurs paramètres (L1, L2)\n",
    "# Le sujet demande de tester différentes régularisations\n",
    "params = {\n",
    "    'C': [0.1, 1, 10],            # Force de la régularisation\n",
    "    'penalty': ['l2'],            # Type de pénalité (l2 est standard et rapide)\n",
    "    'solver': ['lbfgs']           \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), params, cv=5, n_jobs=-1)\n",
    "print(\"Entraînement en cours (patience)...\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 3. Résultats\n",
    "best_model_sentiment = grid.best_estimator_\n",
    "print(f\"Meilleur score : {grid.best_score_:.2%}\")\n",
    "print(f\"Meilleurs paramètres : {grid.best_params_}\")\n",
    "\n",
    "# Test final\n",
    "y_pred = best_model_sentiment.predict(X_test)\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a1e21",
   "metadata": {},
   "source": [
    "# ANALYSE DES THEMES AVEC NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58d90de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thèmes découverts dans les avis :\n",
      "Thème 1: être, ce, le, avoir, je, trop, petit, plus, dommage, tout\n",
      "Thème 2: recevoir, jamais, avoir, produit, ne, colis, non, article, commande, toujours\n",
      "Thème 3: boucle, oreille, de, jolie, lui, bel, très, d, bien, photo\n",
      "Thème 4: qualité, bon, prix, rapport, produit, mauvais, très, bien, super, tre\n",
      "Thème 5: très, joli, bracelet, beau, bel, bien, cadeau, recommander, bijou, conforme\n"
     ]
    }
   ],
   "source": [
    "# On cherche 5 thèmes principaux dans les avis (modifiable avec n_topics)\n",
    "n_topics = 5\n",
    "nmf_model = NMF(n_components=n_topics, init='nndsvd', random_state=42)\n",
    "W = nmf_model.fit_transform(X) # W = Poids des thèmes dans chaque document\n",
    "H = nmf_model.components_      # H = Poids des mots dans chaque thème\n",
    "\n",
    "# Fonction pour afficher les mots clés de chaque thème\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topics[topic_idx] = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        print(f\"Thème {topic_idx + 1}: {', '.join(topics[topic_idx])}\")\n",
    "    return topics\n",
    "\n",
    "print(\"Thèmes découverts dans les avis :\")\n",
    "topics_found = display_topics(nmf_model, features, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c036fe",
   "metadata": {},
   "source": [
    "- Le thème 1 est surement affecter par le bruit (Stopwords mal néttoyer ? (ce, le, je) mais on voit que c'est un thème qui à un rapport avec la taille)\n",
    "\n",
    "- Problème de livraison \n",
    "\n",
    "- Boucle d'oreille (positif largement)\n",
    "\n",
    "- Qualité/Prix\n",
    "\n",
    "- Satisfaction / Cadeau ou recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc284d",
   "metadata": {},
   "source": [
    "# Cette fonction permets de classifier des nouveaux avis que l'on créer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyse de : 'Le produit est cassé et la livraison était en retard, nul.' ---\n",
      "Sentiment : NÉGATIF (Certitude : 77%)\n",
      "Sujet principal (Thème 2) : recevoir, jamais, avoir...\n",
      "------------------------------\n",
      "--- Analyse de : 'J'adore ce collier, il brille vraiment bien et le vendeur est sympa.' ---\n",
      "Sentiment : POSITIF (Certitude : 69%)\n",
      "Sujet principal (Thème 1) : être, ce, le...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyser_nouvel_avis(texte):\n",
    "    # 1. Nettoyage et Vectorisation (on réutilise le vectorizer sauvegardé !)\n",
    "    # Attention: le vectorizer attend une liste, donc on met le texte dans []\n",
    "    # Note: On applique le même prétraitement \"brut\" que le pipeline si possible, \n",
    "    # mais pour l'instant on teste direct.\n",
    "    vec = vectorizer.transform([texte])\n",
    "    \n",
    "    # 2. Prédiction du Sentiment\n",
    "    sentiment = best_model_sentiment.predict(vec)[0]\n",
    "    proba = best_model_sentiment.predict_proba(vec).max()\n",
    "    \n",
    "    # 3. Prédiction du Thème dominant\n",
    "    topic_vec = nmf_model.transform(vec)\n",
    "    topic_id = topic_vec.argmax()\n",
    "    \n",
    "    print(f\"--- Analyse de : '{texte}' ---\")\n",
    "    print(f\"Sentiment : {sentiment.upper()} (Certitude : {proba:.0%})\")\n",
    "    print(f\"Sujet principal (Thème {topic_id + 1}) : {', '.join(topics_found[topic_id][:3])}...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Exemples d'analyse de nouveaux avis\n",
    "analyser_nouvel_avis(\"Le produit est cassé et la livraison était en retard, nul.\")\n",
    "analyser_nouvel_avis(\"J'adore ce collier, il brille vraiment bien et le vendeur est sympa.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
